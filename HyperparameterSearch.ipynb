{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter search\n",
    "This notebook is about the hyperparameter search for our optimal collaborative filtering model.\n",
    "We evaluated the following methods:\n",
    "* Single Factorization\n",
    "* Three-way Factorization\n",
    "* Three-way connected Fractorization\n",
    "* Three-way graph Fractorization\n",
    "* Three-way graph connected Factorization\n",
    "* Four-way graph connected Factorization\n",
    "\n",
    "For differnt hyperparameters, Lambda, Gamma, k (latent space dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload all modules before executing code\n",
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import DB.database as db\n",
    "import src.preprocessing as pre\n",
    "from DB.model import *\n",
    "import src.Solver as Solver\n",
    "import src.MF as MF\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000  #Number of Users\n",
    "M = 100000  #Number of Businesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "friends, relations, business_attributes, BW, UW, word_labels  = db.get_data(N, M, need_business=False, add_words=True, buss_conn_threshold=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test&train data splitting\n",
    "\n",
    "Solver.Dataset keeps the data, creates validation and test indices, 80-10-10 % each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before: (100000, 100000)\n",
      "Shape after: (808, 763)\n"
     ]
    }
   ],
   "source": [
    "relations, user_idx, bus_idx, friends, business_attributes, UW, BW = \\\n",
    "    pre.cold_start_preprocessing(relations, friends, business_attributes, UW=UW, BW=BW, min_entries=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size:(808, 763)\n",
      "Nonzero entries:15863\n",
      "Train:12690, Val:1587, Test:1586\n"
     ]
    }
   ],
   "source": [
    "r_data = Solver.Dataset(relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the test and validation indices of training data =0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input data should be centered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_data = r_data.data.copy()\n",
    "\n",
    "rel_data[r_data.test_ind] = 0\n",
    "rel_data[r_data.val_ind] = 0\n",
    "\n",
    "rel_data, means, _ = Solver.center(rel_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Center Validation Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_val = np.zeros(len(r_data.val_values))\n",
    "for i, val in enumerate(r_data.val_values):\n",
    "    validation_val[i] = val - means[r_data.val_ind[1][i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct business connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_conn = pre.get_buss_conn_mat(M, rel_data, 0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter search\n",
    "Do hyperparamter search across different methods and hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, training_loss: 1209931.209537, review error: 425437.332791, validation loss: 52675.264628\n",
      "Iteration 10, training_loss: 12757.101519, review error: 150.483343, validation loss: 1769.251283\n",
      "Converged after 10 iterations\n",
      "Iteration 0, training_loss: 1232821.482726, review error: 414139.841058, validation loss: 50317.496747\n",
      "Iteration 10, training_loss: 374.866762, review error: 214.459267, validation loss: 1731.045163\n",
      "Iteration 20, training_loss: 321.198603, review error: 196.471091, validation loss: 1712.564921\n",
      "Iteration 30, training_loss: 307.251282, review error: 191.452766, validation loss: 1710.311207\n",
      "Converged after 27 iterations\n",
      "Iteration 0, training_loss: 4035689.987932, review error: 430318.366621, validation loss: 53617.940511\n"
     ]
    }
   ],
   "source": [
    "max_steps = 100\n",
    "log_every = 10\n",
    "eval_every = 1\n",
    "patience = 10\n",
    "\n",
    "lambdas = [0.5, 1, 2, 3]\n",
    "ks = [32, 64, 128, 256]\n",
    "gammas = [0.5, 1, 2, 3]\n",
    "losses = {}\n",
    "\n",
    "for k in ks:\n",
    "    for reg_lambda in lambdas:\n",
    "        for gamma in gammas:\n",
    "            U_three_g, V_three_g, W_three, val_losses, train_loss, conv = \\\n",
    "                MF.three_latent_factor_graph_alternating_optimization(\n",
    "                    friends, business_attributes, rel_data, business_conn, k,\n",
    "                    val_idx = r_data.val_ind, val_values = validation_val,\n",
    "                    reg_lambda=reg_lambda, gamma=gamma, max_steps=max_steps,\n",
    "                    log_every=log_every, patience = patience, eval_every = eval_every)\n",
    "            losses[('three_graph', k, reg_lambda, gamma)] = min(val_losses)\n",
    "            \n",
    "            U_three_gc, V_three_gc, W_three, val_losses, train_loss, conv = \\\n",
    "                MF.three_latent_factor_connected_graph_alternating_optimization(\n",
    "                    friends, business_attributes, rel_data, business_conn, k,\n",
    "                    val_idx = r_data.val_ind, val_values = validation_val,\n",
    "                    reg_lambda=reg_lambda, gamma=gamma, max_steps=max_steps,\n",
    "                    log_every=log_every, patience = patience, eval_every = eval_every)\n",
    "            losses[('three_graph_connected', k, reg_lambda, gamma)] = min(val_losses)\n",
    "            \n",
    "            U_four_gc, V_four_gc, W_four, Z_four, val_losses, train_loss, conv = \\\n",
    "                MF.four_latent_factor_connected_graph_alternating_optimization(\n",
    "                    friends, business_attributes, rel_data, business_conn, UW, BW, k,\n",
    "                    val_idx = r_data.val_ind, val_values = validation_val,\n",
    "                    reg_lambda=reg_lambda, gamma=gamma, max_steps=max_steps,\n",
    "                    log_every=log_every, patience = 3, eval_every = eval_every)\n",
    "            losses[('four_graph_connected', k, reg_lambda, gamma)] = min(val_losses)\n",
    "            \n",
    "        U_single, V_single, val_losses ,_ ,_ = \\\n",
    "            MF.latent_factor_alternating_optimization(rel_data, r_data.train_ind,\n",
    "                k, val_idx = r_data.val_ind, val_values = validation_val,\n",
    "                reg_lambda=reg_lambda, max_steps=max_steps, init='random',\n",
    "                log_every=log_every, patience=patience, eval_every=eval_every)\n",
    "        losses[('single', k, reg_lambda)] = min(val_losses)\n",
    "        \n",
    "        U_three, V_three, W_three, val_losses, train_loss, conv = \\\n",
    "            MF.three_latent_factor_alternating_optimization(\n",
    "                friends, business_attributes, rel_data, k,\n",
    "                val_idx = r_data.val_ind, val_values = validation_val,\n",
    "                reg_lambda=reg_lambda, max_steps=max_steps,\n",
    "                log_every=log_every, patience = patience, eval_every = eval_every)\n",
    "        losses[('three', k, reg_lambda)] = min(val_losses)\n",
    "        \n",
    "        U_three_c, V_three_c, W_three, val_losses, train_loss, conv = \\\n",
    "            MF.three_latent_factor_connected_alternating_optimization(\n",
    "                friends, business_attributes, rel_data, business_conn, k,\n",
    "                val_idx = r_data.val_ind, val_values = validation_val,\n",
    "                reg_lambda=reg_lambda, max_steps=max_steps,\n",
    "                log_every=log_every, patience = patience, eval_every = eval_every)\n",
    "        losses[('three_connected', k, reg_lambda)] = min(val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(losses.values()))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(losses.keys()))[np.array(list(losses.values())).argsort()[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business-Business connections\n",
    "For our business business connection matrix we introduced a few hyperparamters during the construction. One for a maximal rating distance between two reviews to form a connection and one for a minimal number of users to form a connection.\n",
    "\n",
    "In the following we are performing a hyperparameter search for our best method from the previous search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got users\n",
      "Got businesses\n",
      "Got reviews\n"
     ]
    }
   ],
   "source": [
    "database = db.Database()\n",
    "database.__enter__()\n",
    "users, businesses, reviews, category_names, cities = db.get_entities(database, N, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0, 1, 2, 3, 4]\n",
    "min_users = [1, 2, 4, 7, 10, 15]\n",
    "thres_losses = {}\n",
    "best_U = None\n",
    "best_V = None\n",
    "min_loss = -1\n",
    "\n",
    "# Query\n",
    "friends, relations, business_attributes  = \\\n",
    "    DB.get_matrices(users, businesses, reviews, category_names, cities)\n",
    "\n",
    "# Cut\n",
    "relations_cut, _, bus_idx, friends, business_attributes = \\\n",
    "    pre.cold_start_preprocessing(relations, friends, business_attributes, min_entries=10)\n",
    "\n",
    "# Split\n",
    "r_data = Solver.Dataset(relations_cut)\n",
    "\n",
    "rel_data = r_data.data\n",
    "\n",
    "rel_data[r_data.test_ind] = 0\n",
    "rel_data[r_data.val_ind] = 0\n",
    "\n",
    "# Center\n",
    "rel_data, means, _ = Solver.center(rel_data)\n",
    "\n",
    "validation_val = np.zeros(len(r_data.val_values))\n",
    "for i, val in enumerate(r_data.val_values):\n",
    "    validation_val[i] = val - means[r_data.val_ind[1][i]]\n",
    "\n",
    "for min_user in min_users:\n",
    "    for threshold in thresholds:            \n",
    "        business_conn = pre.get_buss_conn_mat(M, rel_data, threshold, min_user)\n",
    "        print('Min user %i; Threshold %i; Entries %i ' % (min_user, threshold, business_conn.nnz))\n",
    "\n",
    "        # Evaluate\n",
    "        U_three_gc, V_three_gc, W_three, val_losses, train_loss, conv = \\\n",
    "            MF.three_latent_factor_connected_graph_alternating_optimization(\n",
    "                friends, business_attributes, rel_data, business_conn, 256,\n",
    "                val_idx = r_data.val_ind, val_values = validation_val,\n",
    "                reg_lambda=2, gamma=1, max_steps=100,\n",
    "                log_every=1, patience = 10, eval_every = 1)\n",
    "        \n",
    "        loss = min(val_losses)\n",
    "        thres_losses[(min_user, threshold)] = loss\n",
    "        if loss < min_loss or min_loss == -1:\n",
    "            best_U = U_three_gc\n",
    "            best_V = V_three_gc\n",
    "            min_loss = loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(thres_losses.values()))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(thres_losses.keys()))[np.array(list(thres_losses.values())).argsort()[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Solver.RMSE(best_U, best_V, r_data.test_ind, r_data.test_values, means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_factorization.pickle', 'wb') as f:\n",
    "    pickle.dump((best_U, best_V), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
